{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf3c468",
   "metadata": {},
   "source": [
    "# Weather forecast Automation\n",
    "\n",
    "\n",
    "In this tutorial I will teach you how to webscrape an html site to get your local weather (or from where ever you want) using web scraping.\n",
    "\n",
    "Goals:\n",
    "- Get your local weather by webscraping\n",
    "- Web scrape certain attributes from the html source\n",
    "- Create a csv with our weather data\n",
    "\n",
    "\n",
    "URL that will be used:\n",
    "- https://forecast.weather.gov/MapClick.php?lat={}&lon=-{}#.X79gyqpKhQI\n",
    "    - {} we will fill in with our longitutde and latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638e5f8",
   "metadata": {},
   "source": [
    "### Libraries that will be used:\n",
    "- requests\n",
    "    - The requests module allows you to send HTTP requests using Python. The HTTP request returns a Response Object with all the response data (content, encoding, status, etc).\n",
    "    \n",
    "- pandas\n",
    "    - It provides ready to use high-performance data structures and data analysis tools. Pandas module runs on top of NumPy and it is popularly used for data science and data analytics.\n",
    "    \n",
    "- beautifulsoup\n",
    "    - Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f207f",
   "metadata": {},
   "source": [
    "### Get your local longitude and latitude\n",
    "\n",
    "Before we begin, you want to get your longitude and lattitude of your desired place to get weather data.\n",
    "\n",
    "You will pass in the long and latitude when you call the class, you can do this with different places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34584b7a",
   "metadata": {},
   "source": [
    "### Get Requests and Check Page Status\n",
    "\n",
    "When we begin accessing web pages and API's we may need to check if the URL is reachable, check server status, check if image URL is working and so on. \n",
    "\n",
    "So what we will do is ping the URL and get a response code to determine if the URL is working or not. \n",
    "\n",
    "Goals for this function:\n",
    "- Make sure our url from the previous step is accessable\n",
    "- Get a 200 status code\n",
    "    - Want to learn more about status codes, I will provide some links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4f919",
   "metadata": {},
   "source": [
    "### Web Scaping \n",
    "**2 parts**\n",
    "\n",
    "Now that we have checked our page status and are able to access it sucessfully, we can begin with web scaping to get our forecast.\n",
    "\n",
    "Goals for Part 1 (7 Day forecast):\n",
    "- Parse page\n",
    "- Locate html section that contains the 7 day forecast\n",
    "    - Get all data for that\n",
    "This will be used to pass on to write to a csv file\n",
    "------\n",
    "Goals for Part 2 (single day forecast):\n",
    "- Get weather for today\n",
    "    - We can also get weather for the whole week\n",
    "- Extract text for our forecast\n",
    "- Extract description\n",
    "- Get temperature\n",
    "These exta ones are for single day forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058b69b",
   "metadata": {},
   "source": [
    "### Data to CSV\n",
    "\n",
    "Now that we have our weather data, we want to get our day for the 7 day forecast.\n",
    "\n",
    "Similar to part 2 in web scraping, we will use the same concepts, but this time we want to use it for the full week instead of one day.\n",
    "\n",
    "Goals:\n",
    "- Use list comprehension\n",
    "- Get the appropriate tags\n",
    "    - Get the day names\n",
    "    - Get the short descriptions\n",
    "    - Get temperatures\n",
    "    - Get descriptions\n",
    "- Add all this data to a dataframe\n",
    "- Convert dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1abed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import requests as rq # set requests alias as rq\n",
    "    import pandas as pd # set pandas alias as pd\n",
    "    from bs4 import BeautifulSoup as bss # set beautifulsoup alias as bss\n",
    "\n",
    "    ## print('[SUCCESSFULLY IMPORTED]')\n",
    "    ## return nothing for a succesful import\n",
    "except ImportError as ie:\n",
    "    print(f'Import Library Error: {ie}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b107b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherForecast:\n",
    "    '''Class will always require you to pass in longitutde and latitude'''\n",
    "    def __init__(self,latitude, longitude):\n",
    "        pass\n",
    "        \n",
    "    def get_long_lat(self): \n",
    "        '''Accessing this alone will give us a working link'''\n",
    "        pass\n",
    "    \n",
    "    def check_url_status(self):\n",
    "        '''Check the status of the URL\n",
    "        - if 200, this means its in good status and we can access it'''\n",
    "        pass\n",
    "            \n",
    "    def get_weather_data_7_day(self):\n",
    "        '''Get weather data for the week'''\n",
    "        pass\n",
    "    \n",
    "    def get_single_day_weather_data(self): # Function isn't necessary for automation portion\n",
    "        '''Get all the forecast'''\n",
    "        pass\n",
    "        \n",
    "    def weather_data_to_csv(self):\n",
    "        '''Here we will get the tag names, days, descripitions, and weather'''\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182d9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    long = 39.1911\n",
    "    lat = 106.8175\n",
    "    wf = WeatherForecast(long, lat)\n",
    "    funcs = [\n",
    "        wf.get_long_lat(), \n",
    "        wf.check_url_status(),\n",
    "        wf.get_weather_data_7_day(), \n",
    "        wf.get_single_day_weather_data(),\n",
    "        wf.weather_data_to_csv()\n",
    "    ]\n",
    "    \n",
    "    # We can test each of our functions\n",
    "    for func in funcs:\n",
    "        print(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f41fc67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f1e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
